{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "os.cpu_count(): 20\n",
      "GPU 0: NVIDIA GeForce RTX 4070 SUPER (UUID: GPU-b10c6cac-b9b4-49fa-2e4d-8ba5c4c711ba)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from contextlib import nullcontext\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from cycler import cycler; plt.rcParams[\"axes.prop_cycle\"] = cycler(color=[\"#000000\", \"#2180FE\", \"#EB4275\"])\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(f'device: {device}')\n",
    "print(f'os.cpu_count(): {os.cpu_count()}')\n",
    "!nvidia-smi -L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cube import Cube\n",
    "env = Cube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (embedding): LinearBlock(\n",
       "    (fc): Linear(in_features=324, out_features=5000, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (bn): BatchNorm1d(5000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (linear_layers): ModuleList(\n",
       "    (0): LinearBlock(\n",
       "      (fc): Linear(in_features=5000, out_features=1000, bias=True)\n",
       "      (relu): ReLU()\n",
       "      (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (residual_blocks): ModuleList(\n",
       "    (0-3): 4 x ResidualBlock(\n",
       "      (layers): ModuleList(\n",
       "        (0-1): 2 x LinearBlock(\n",
       "          (fc): Linear(in_features=1000, out_features=1000, bias=True)\n",
       "          (relu): ReLU()\n",
       "          (bn): BatchNorm1d(1000, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (output): Linear(in_features=1000, out_features=12, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from model import Model\n",
    "model = Model()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: torch.Size([1000, 26, 54])\n",
      "y shape: torch.Size([1000, 26])\n",
      "X dtype: torch.int64\n",
      "y dtype: torch.int64\n",
      "Sample X: tensor([[0, 0, 0,  ..., 2, 5, 5],\n",
      "        [0, 0, 0,  ..., 2, 5, 3],\n",
      "        [5, 3, 4,  ..., 2, 5, 3],\n",
      "        ...,\n",
      "        [3, 5, 0,  ..., 0, 3, 0],\n",
      "        [0, 3, 0,  ..., 0, 3, 0],\n",
      "        [4, 3, 0,  ..., 0, 5, 4]])\n",
      "Sample y: tensor([ 1,  0,  9,  6,  6, 10,  5,  6, 10, 10,  9,  4,  4,  8,  4, 11,  0,  7,\n",
      "         2,  0,  4,  3, 10,  2,  3, 10])\n",
      "Sample y: tensor([ 5,  0,  9,  0,  2, 11,  4,  7,  2,  3,  7,  2,  9,  0,  2,  1,  8,  6,\n",
      "         4,  8,  5,  2, 10,  5,  5,  2])\n"
     ]
    }
   ],
   "source": [
    "from config import TrainConfig\n",
    "\n",
    "\n",
    "class ScrambleGenerator(torch.utils.data.Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_workers=os.cpu_count(),\n",
    "        max_depth=TrainConfig.max_depth,\n",
    "        total_samples=TrainConfig.num_steps*TrainConfig.batch_size_per_depth\n",
    "    ):\n",
    "        self.num_workers = num_workers\n",
    "        self.max_depth = max_depth\n",
    "        # self.envs = [Cube() for _ in range(num_workers)]\n",
    "        # self.generators = [env.scrambler(self.max_depth) for env in self.envs]\n",
    "\n",
    "        self.total_samples = total_samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.total_samples\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        ''' generate one scramble, consisting of `self.max_depth` data points '''\n",
    "        # worker_idx = i % self.num_workers\n",
    "        try:\n",
    "            X = np.zeros((self.max_depth, 54), dtype=np.int64)\n",
    "            y = np.zeros((self.max_depth,), dtype=np.int64)\n",
    "            generator = Cube().scrambler(self.max_depth)\n",
    "            for j in range(self.max_depth):\n",
    "                state, last_move = next(generator)\n",
    "                X[j, :] = state\n",
    "                y[j] = last_move\n",
    "            return X, y\n",
    "        except Exception as e:\n",
    "            print(f'error: {e}')\n",
    "            return self.__getitem__(i)\n",
    "\n",
    "\n",
    "dataloader = torch.utils.data.DataLoader(\n",
    "    ScrambleGenerator(),\n",
    "    num_workers=0,\n",
    "    batch_size=TrainConfig.batch_size_per_depth\n",
    ")\n",
    "\n",
    "# Get one batch from the dataloader\n",
    "sample_batch = next(iter(dataloader))\n",
    "\n",
    "# Unpack X and y from the batch\n",
    "X, y = sample_batch\n",
    "\n",
    "# Check shapes and data types\n",
    "print(\"X shape:\", X.shape)  # Expected: (batch_size, max_depth, 54)\n",
    "print(\"y shape:\", y.shape)  # Expected: (batch_size, max_depth)\n",
    "print(\"X dtype:\", X.dtype)\n",
    "print(\"y dtype:\", y.dtype)\n",
    "\n",
    "# Optional: Print the first few entries to inspect contents\n",
    "print(\"Sample X:\", X[0])  # Print the first sample in X\n",
    "print(\"Sample y:\", y[0])  # Print the first sample in y\n",
    "print(\"Sample y:\", y[1])  # Print the first sample in y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training is disabled\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scarlet1ssimo\\AppData\\Local\\Temp\\ipykernel_55032\\515275775.py:49: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('10000steps.pth'))\n"
     ]
    }
   ],
   "source": [
    "def plot_loss_curve(h):\n",
    "    fig, ax = plt.subplots(1, 1)\n",
    "    ax.plot(h)\n",
    "    ax.set_xlabel(\"Steps\")\n",
    "    ax.set_ylabel(\"Cross-entropy loss\")\n",
    "    ax.set_xscale(\"log\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train(model, dataloader):\n",
    "    model.train()\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(\n",
    "        model.parameters(), lr=TrainConfig.learning_rate)\n",
    "    g = iter(dataloader)\n",
    "    h = []\n",
    "    ctx = torch.cuda.amp.autocast(\n",
    "        dtype=torch.float16) if TrainConfig.ENABLE_FP16 else nullcontext()\n",
    "\n",
    "    for i in trange(1, TrainConfig.num_steps + 1):\n",
    "        batch_x, batch_y = next(g)\n",
    "        batch_x, batch_y = batch_x.reshape(-1,\n",
    "                                           54).to(device), batch_y.reshape(-1).to(device)\n",
    "\n",
    "        with ctx:\n",
    "            pred_y = model(batch_x)\n",
    "            loss = loss_fn(pred_y, batch_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        h.append(loss.item())\n",
    "        if TrainConfig.INTERVAL_PLOT and i % TrainConfig.INTERVAL_PLOT == 0:\n",
    "            clear_output()\n",
    "            plot_loss_curve(h)\n",
    "        if TrainConfig.INTERVAL_SAVE and i % TrainConfig.INTERVAL_SAVE == 0:\n",
    "            torch.save(model.state_dict(), f\"{i}steps.pth\")\n",
    "            print(\"Model saved.\")\n",
    "    print(\n",
    "        f\"Trained on data equivalent to {TrainConfig.batch_size_per_depth * TrainConfig.num_steps} solves.\")\n",
    "    return model\n",
    "\n",
    "\n",
    "train_here = False\n",
    "if train_here:\n",
    "    model = train(model, dataloader)\n",
    "else:\n",
    "    print('training is disabled')\n",
    "    model.load_state_dict(torch.load('10000steps.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 100.00%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 100.00%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 100.00%\n",
      "Accuracy for subtask: 25 / 26 = 96.15%. Total accuracy: 99.04%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.23%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.36%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.45%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.52%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.57%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.62%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.65%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.68%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.70%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.73%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.74%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.76%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.77%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.79%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.80%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.81%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.82%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.83%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.83%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.84%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 25 / 26 = 96.15%. Total accuracy: 99.73%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.73%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.74%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.75%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.76%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.77%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.77%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.78%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.79%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.79%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.80%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.80%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.81%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.81%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.82%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.82%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.83%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.83%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.83%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.84%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.84%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.84%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.85%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.89%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.90%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.91%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.91%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.91%\n",
      "Accuracy for subtask: 25 / 26 = 96.15%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.86%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.87%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 26 / 26 = 100.00%. Total accuracy: 99.88%\n",
      "Accuracy for subtask: 25 / 26 = 96.15%. Total accuracy: 99.85%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9984615384615385"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate Accuracy\n",
    "def validate(model, num_samples=100):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    cnt = 0\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_samples):\n",
    "            env = Cube()\n",
    "            generator = env.scrambler(TrainConfig.max_depth)\n",
    "            sub_correct = 0\n",
    "            sub_cnt = 0\n",
    "            for i in range(TrainConfig.max_depth):\n",
    "                state, move = next(generator)\n",
    "                pred = model(torch.tensor(state, dtype=torch.int64).to(\n",
    "                    device)).argmax().item()\n",
    "                if pred == move:\n",
    "                    sub_correct += 1\n",
    "                sub_cnt+=1\n",
    "            correct += sub_correct\n",
    "            cnt += sub_cnt\n",
    "            print(f\"Accuracy for subtask: {sub_correct} / {sub_cnt} = {sub_correct/sub_cnt:.2%}. Total accuracy: {correct / cnt:.2%}\")\n",
    "    return correct / cnt\n",
    "\n",
    "\n",
    "validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Scarlet1ssimo\\Documents\\444\\final\\DeepCubeA\n",
      "### Optimal Solver ###\n",
      "dict_keys(['states', 'times', 'solutions', 'num_nodes_generated'])\n",
      "No. of cases: 1000\n",
      "\n",
      "### DeepCubeA ###\n",
      "dict_keys(['states', 'solutions', 'paths', 'times', 'num_nodes_generated'])\n",
      "No. of cases: 1000\n",
      "c:\\Users\\Scarlet1ssimo\\Documents\\444\\final\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Scarlet1ssimo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "if \"DeepCubeA\"!=os.getcwd().split(\"/\")[-1]:\n",
    "    if not os.path.exists('DeepCubeA'):\n",
    "        !git clone -q https://github.com/forestagostinelli/DeepCubeA\n",
    "    %cd ./DeepCubeA/\n",
    "\n",
    "print('### Optimal Solver ###')\n",
    "filename = 'data/cube3/test/data_0.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    result_Optimal = pickle.load(f)\n",
    "\n",
    "    print(result_Optimal.keys())\n",
    "    result_Optimal[\"solution_lengths\"] = [len(s) for s in result_Optimal[\"solutions\"]]\n",
    "    result_Optimal[\"solution_lengths_count\"] = {\n",
    "        i: result_Optimal[\"solution_lengths\"].count(i)\n",
    "        for i in range(min(result_Optimal[\"solution_lengths\"]), max(result_Optimal[\"solution_lengths\"]))\n",
    "    }\n",
    "\n",
    "    print('No. of cases:', len(result_Optimal[\"solution_lengths\"]))\n",
    "\n",
    "print('\\n### DeepCubeA ###')\n",
    "filename = 'results/cube3/results.pkl'\n",
    "with open(filename, 'rb') as f:\n",
    "    result_DeepCubeA = pickle.load(f)\n",
    "\n",
    "    print(result_DeepCubeA.keys())\n",
    "    result_DeepCubeA[\"solution_lengths\"] = [len(s) for s in result_DeepCubeA[\"solutions\"]]\n",
    "    result_DeepCubeA[\"solution_lengths_count\"] = {\n",
    "        i: result_DeepCubeA[\"solution_lengths\"].count(i)\n",
    "        for i in range(min(result_DeepCubeA[\"solution_lengths\"]), max(result_DeepCubeA[\"solution_lengths\"]))\n",
    "    }\n",
    "\n",
    "    print('No. of cases:', len(result_DeepCubeA[\"solution_lengths\"]))\n",
    "\n",
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example:\n",
      "[['D', -1], ['F', 1], ['R', 1], ['U', -1], ['F', 1], ['F', 1], ['R', 1], ['U', 1], ['F', 1], ['R', 1], ['B', -1], ['R', -1], ['F', -1], ['R', -1], ['D', -1], ['U', -1], ['R', -1], ['U', -1], ['U', -1], ['R', -1], ['U', 1], ['B', -1]]\n",
      "-> ['B', \"U'\", 'R', 'U', 'U', 'R', 'U', 'D', 'R', 'F', 'R', 'B', \"R'\", \"F'\", \"U'\", \"R'\", \"F'\", \"F'\", 'U', \"R'\", \"F'\", 'D']\n"
     ]
    }
   ],
   "source": [
    "# Convert optimal solutions to test scrambles\n",
    "def solution2scramble(solution):\n",
    "    return [m[0] if m[1] == -1 else m[0] + \"'\" for m in solution[::-1]]\n",
    "\n",
    "test_scrambles = [solution2scramble(s) for s in result_Optimal[\"solutions\"]]\n",
    "\n",
    "print(f\"\"\"Example:\\n{result_Optimal[\"solutions\"][0]}\\n-> {test_scrambles[0]}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import SearchConfig\n",
    "from cube import QTM\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def beam_search(\n",
    "    env,\n",
    "    model,\n",
    "    beam_width=SearchConfig.beam_width,\n",
    "    max_depth=SearchConfig.max_depth,\n",
    "    skip_redundant_moves=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Best-first search algorithm.\n",
    "    Input:\n",
    "        env: A scrambled instance of the given environment.\n",
    "        model: PyTorch model used to predict the next move(s).\n",
    "        beam_width: Number of top solutions to return per depth.\n",
    "        max_depth: Maximum depth of the search tree.\n",
    "        skip_redundant_moves: If True, skip redundant moves.\n",
    "    Output:\n",
    "        if solved successfully:\n",
    "            True, {'solutions':solution path, \"num_nodes_generated\":number of nodes expanded, \"times\":time taken to solve}\n",
    "        else:\n",
    "            False, None\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.cuda.amp.autocast(dtype=torch.float16) if SearchConfig.ENABLE_FP16 else nullcontext():\n",
    "        # metrics\n",
    "        num_nodes_generated, time_0 = 0, time.time()\n",
    "        candidates = [\n",
    "            {\"state\": deepcopy(env.state), \"path\": [], \"value\": 1.}\n",
    "        ]  # list of dictionaries\n",
    "\n",
    "        for depth in range(max_depth+1):\n",
    "            # TWO things at a time for every candidate: 1. check if solved & 2. add to batch_x\n",
    "            batch_x = np.zeros(\n",
    "                (len(candidates), env.state.shape[-1]), dtype=np.int64)\n",
    "            for i, c in enumerate(candidates):\n",
    "                c_path, env.state = c[\"path\"], c[\"state\"]\n",
    "                if c_path:\n",
    "                    env.move(c_path[-1])\n",
    "                    num_nodes_generated += 1\n",
    "                    if env.is_solved():\n",
    "                        # Revert: array of indices => array of notations\n",
    "                        c_path = [str(env.mode.NUM2CHAR[i]) for i in c_path]\n",
    "                        return True, {'solutions': c_path, \"num_nodes_generated\": num_nodes_generated, \"times\": time.time()-time_0}\n",
    "                batch_x[i, :] = env.state\n",
    "\n",
    "            # after checking the nodes expanded at the deepest\n",
    "            if depth == max_depth:\n",
    "                print(\"Solution not found.\")\n",
    "                return False, None\n",
    "\n",
    "            # make predictions with the trained DNN\n",
    "            batch_x = torch.from_numpy(batch_x).to(device)\n",
    "            batch_p = model(batch_x)\n",
    "            batch_p = torch.nn.functional.softmax(batch_p, dim=-1)\n",
    "            batch_p = batch_p.detach().cpu().numpy()\n",
    "\n",
    "            # loop over candidates\n",
    "            # storage for the depth-level candidates storing (path, value, index).\n",
    "            candidates_next_depth = []\n",
    "            for i, c in enumerate(candidates):\n",
    "                c_path = c[\"path\"]\n",
    "                # output logits for the given state\n",
    "                value_distribution = batch_p[i, :]\n",
    "                # multiply the cumulative probability so far of the expanded path\n",
    "                value_distribution *= c[\"value\"]\n",
    "\n",
    "                # iterate over all possible moves.\n",
    "                for j, value in enumerate(value_distribution):\n",
    "                    # predicted value to expand the path with the given move.\n",
    "\n",
    "                    if c_path and skip_redundant_moves:\n",
    "                        if j not in env.mode.MOVES_NO_CANCEL[c_path[-1]]:\n",
    "                            # Two mutually canceling moves\n",
    "                            continue\n",
    "                        elif len(c_path) > 1:\n",
    "                            # if c_path[-2] == c_path[-1] == m:\n",
    "                            if c_path[-2] == c_path[-1] == j:\n",
    "                                # Three subsequent moves that could be one\n",
    "                                continue\n",
    "                            # elif (\n",
    "                            #     c_path[-2][0] == m[0] and len(c_path[-2] + m) == 3\n",
    "                            #     and c_path[-1][0] == env.pairing[m[0]]\n",
    "                            # ):\n",
    "                            # elif env.mode.isOpposite(c_path[-2], c_path[-1]) and env.mode.isSameFace(j, c_path[-2]):\n",
    "                                # Two mutually canceling moves sandwiching an opposite face move\n",
    "                                # continue\n",
    "\n",
    "                    # add to the next-depth candidates unless 'continue'd.\n",
    "                    candidates_next_depth.append({\n",
    "                        'state': deepcopy(c['state']),\n",
    "                        \"path\": c_path+[j],\n",
    "                        \"value\": value,\n",
    "                    })\n",
    "\n",
    "            # sort potential paths by expected values and renew as 'candidates'\n",
    "            candidates = sorted(candidates_next_depth,\n",
    "                                key=lambda item: -item['value'])\n",
    "            # if the number of candidates exceed that of beam width 'beam_width'\n",
    "            candidates = candidates[:beam_width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "U'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "scramble=\"U' R\"\n",
    "env.reset()\n",
    "env.apply(scramble)\n",
    "model.eval()\n",
    "x=env.get_state().reshape(1,-1)\n",
    "x=np.array(x,dtype=np.int64)\n",
    "y=model(torch.from_numpy(x).to(device)).argmax().item()\n",
    "print(env.mode.NUM2CHAR[env.mode.getCancel(y)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1000 [00:04<1:13:01,  4.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution not found.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/1000 [00:09<1:16:49,  4.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solution not found.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "result_ours = {\n",
    "    \"solutions\":[],\n",
    "    \"num_nodes_generated\":[],\n",
    "    \"times\":[]\n",
    "}\n",
    "for scramble in tqdm(test_scrambles, position=0):\n",
    "    # reset and scramble\n",
    "    env.reset()\n",
    "    env.apply(scramble)\n",
    "    # solve\n",
    "    success, result = beam_search(env, model)\n",
    "    if success:\n",
    "        for k in result_ours.keys():\n",
    "            result_ours[k].append(result[k])\n",
    "    else:\n",
    "        result_ours[\"solutions\"].append(None)\n",
    "\n",
    "result_ours['solution_lengths'] = [len(e) for e in result_ours['solutions'] if e]\n",
    "result_ours['solution_lengths_count'] = {\n",
    "    i: result_ours[\"solution_lengths\"].count(i)\n",
    "    for i in range(min(result_ours[\"solution_lengths\"]), max(result_ours[\"solution_lengths\"]))\n",
    "}\n",
    "f\"Successfully solved {len(result_ours['times'])} cases out of {len(result_ours['solutions'])}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
